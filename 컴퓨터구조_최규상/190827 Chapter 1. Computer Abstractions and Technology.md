- # 190827 Chapter 1. Computer Abstractions and Technology

  ## 1.1 Introduction

  무어의 법칙 -> 매년 2배 이상 칩의 성능이 증가.

  ### Understanding Performance

  각각의 관점에 따라 성능이 다르게 정의된다.

  - Algorithm - operation의 수가 적으면 좋은 것
  - Programming language, compiler, architecture - instruction(실제 CPU가 수행하는 명령어, operation보다 구체적)의 수가 적으면 좋은 것
  - Processor and memory system - 얼마나 빨리 instruction이 실행되는가
  - I/O system - 단위 시간 당 얼마나 많은 I/O operation이 실행되는가

  ## 1.2 Eight Great Ideas in Computer Architecture

  컴퓨터의 성능 향상에 지대한 공헌을 한 것들

  1. Moore's Law
  2. abstraction
  3. make the common case fast
  4. performance via parallelism
  5. performance via pipelining
  6. performance via prediction
  7. hierarchy of memories
  8. dependability via redundancy(RAID in 6장)

  ### Below Your Program

  - Application software
  - System software - 운영체제(handling I/O, memory and storage, scheduling tasks & sharing resources), 컴파일러(high lvl code -> machine code) 등 프로그램 실행하는 데 기본적인 소프트웨어
  - Hardware - Processor, memory, I/O controllers

  ### Levels of Program Code

  - High-level language
  - Assembly language - Textual representation of instructions. 어셈블러라는 프로그램을 통해 머신 코드(바이너리 코드)로 바뀌게 됨
  - Hardware representation - Binary digits(bits)

  비쥬얼스튜디오에는 컴파일러와 어셈블러가 함께 탑재되어 있다.

  ## 1.4 Under the Covers

  ### Inside the Processor(CPU)

  - Datapath - 데이터의 흐름 제어
  - Contrtol - 컨트롤
  - Cache memory - CPU 내의 SRAM으로 구성된 캐시 메모리에 자주 사용하는 데이터를 올려놔서 빨리 엑세스할 수 있게 함.

  ### Abstracitons(추상화)

  복잡한 문제를 풀 때 추상화 기법을 사용하면 효과적. 단순화하여 쉽게 풀 수 있게 함.

  ex) Instruction Set Architecture(ISA) - hardware/software interface

  - Application binary interface(ABI) - ISA와 시스템 소프트웨어의 인터페이스
  - Implementation - ISA를 실제로 어떻게 구현할 것인가?

  ### A Safe Place for Data

  - Volatile main memory

    휘발성.

  - Non-volatile seconary

    - Magnetic disk
    - Flash memory
    - Optical Disk

  ### Networks

  ## 1.5 Technologies for Building Processors and Memory

  메모리에 대해 좀 더 알아보자.

  무어의 법칙과도 연관하여, 시간이 지날수록 DRAM의 Capacity가 급격하게 증가해왔다.

  시간이 지남에 따라 성능이 급격하게 향상됨.

  ### Semiconductor Technology

  Silicon: semiconductor

  실리콘에 기판을 새겨넣는 것.

  Add materials to transform properties:

  - Conductors
  - Insulators
  - Switch

  ### Manufacturing ICs

  Silicon ingot을 얇게 썰어서 웨이퍼를 만들고 가공을 해서 패턴을 만듦. 그걸 테스트하고, dies해서 package를 반들고, 이걸로 칩을 만든다. 각각의 칩들이 제대로 동작하는지 체크 -> 실제 customer에게 판매

  - Yield: 하나의 웨이퍼당 동작하는 die의 포션

  웨이퍼 하나에 여러 개의 칩이 들어간다. 수율은 하나의 웨이퍼 당 몇개의 칩이 성공하는가.

  ## 1.6 Performance

  ### Response Time and Throughput

  컴퓨터에서 성능을 어떻게 정의할 것인가

  - Response time : 어떤 하나의 task를 하는 데 걸리는 시간
  - Throughput : 단위 시간 당 얼마나 많은 일을 할 수 있는가. e.g. tasks/transactions/... per hour

  더 빠른 CPU(processor)를 쓴다면? -> response time, throughput이 모두 개선된다

  여러 개의 CPU(processor)를 쓴다면? -> 하나의 프로세서에서 처리하는 시간은 늘지 않는다(response time은 그대로) but throughput은 여러 코어에서 동시에 일을 할 수 있기 때문에 Throughput은 개선.

  일반적으로 response time을 줄이면 throughput은 같이 개선된다. but 역은 성립하지 않을 수도.

  따라서 우리는 response time에 집중하여, 성능은 response time으로 볼 것.

  ### Relative Performance

  Define Performance = 1/Execution Time

  "X is n time faster than Y"

  <=> Performance(x) / Performance(y) = Execution time(y) / Execution time(x) = n

  - performance와 execution time은 반비례 관계!

  e.g. 10s on A, 15s on B

  => A is 1.5 times faster than B

  ### Measuring Execution Time

  - Elapsed time

    걸린 시간. Total response time. 어떤 오퍼레이션을 수행하는 데 걸린 시간(CPU, I/O, OS overhead, idle time을 모두 포함)

    Determines system performance

  - CPU time

    어떤 일을 처리할 때 CPU에서 걸리는 시간 . I/O time, other job's shares를 제외

    user CPU time / system CPU time(운영체제에서 걸린 시간)으로 나뉘어짐

    어떤 프로그램은 CPU 영향을, 어떤 프로그램은 I/O의 영향을 많이 받을 수 있다.

  ### CPU Clocking

  **Clock period(Clock cycle time)** 하나의 라이딩 엣지에서 다음 라이딩 엣지까지. duration of a clock cycle

  e.g. 250ps(피코 세컨드) = 0.25ns = 250 x 10^(-12)s

  Clock frequency: cycles per second

  e.g. 4.0GHz = 4000MHz = 4.0 x 10^9Hz

  **기본적인 단위를 기억하자!**

  ### Review: Machine Clock Rate

  **Clock rate**(clock cycles per second in MHz or GHz) is inverse of clock cycle time(**clock period**)

  CC = 1 / CR

  ### CPU Time

  CPU Time = CPU Clock cycle x Clock cycle Time = (CPU Clock cycles / Clock cycle time)

  - Performance improved by
    - clock cycles를 줄인다
    - clock rate를 늘린다
    - 하드웨어 디자이너는 clock rate를 cycle count를 trade-off 해야함

  Clock Rate이 4GHz여야 6초에 주어진 일을 할 수 있다.

  ### Instruction Count and CPI

  Clock Cycles = Instruction Count x Cycles per Instruction(CPI)

  CPU Time = Instruction Count x CPI x Clock cycle time = (Instruction Count x CPI) / (Clock Rate)

  - Instruction Count for program

    Determined by program, ISA and Complier

  - Average cycles per instruction

    - Determined by CPU hardware
    - If different instructions have different CPI
      - Average CPI affected by instruction mix

  ### CPI Example

  if (CPU Time(b)) / (CPU Time(a)) = 1.2:

   컴퓨터 a가 컴퓨터 b보다 1.2배 빠르다

  ### Performance Summary

  **The BIG Picture**

  CPU Time = Instructions x Clock cycles x Seconds

  - Performance depends on
    - 알고리즘 : IC(, CPI)
    - 프로그래밍 언어 : IC, CPI
    - 컴파일러 : IC, CPI
    - ISA : IC, CPI, Tc(Clock Cycle Time)

  ## 1.7 The Power Wall

  ### Power Trends

  Clock rate은 지속적으로 증가해왔다가 2004년부터는 잘 늘지 않는다. Power는 늘다가 2004년부터 완만하게 줄었다.

  In CMOS IC technology:

   Power = Capacitive load x Voltage^2 x Frequency

  Clock rate이 더이상 증가하지 않은 이유는 Power가 줄은 것에 기인.

  ### Reducing Power

  - The power wall : 전력을 더 이상 낮추기 어렵다. 거기서 발생하는 열을 줄일 수 없다.
  - Clock rate을 증가시키는 방법 외에, 어떤 방법으로 퍼포먼스를 향상시킬 수 있을까?(since 2004)

  ## 1.8 the switch

  ### Uniprocessors

  전력, instruction-level parallelism, memory latency 때문에 2004년부터 clock rate을 증가시키는 데 한계가 발생

  ### Multiprocessors

  칩 하나에 여러 개의 프로세서

  - 멀티 코어에서는 패러랠 프로그래밍을 써야 성능 향상을 도모할 수 있다.
    - compare with instruction level parallelism
      - 하드웨어가 알아서 instruction을 처리해줌
      - 프로그래머는 신경쓰지 않아도 됨
    - but Hard to do
      - Programming for performance
      - load balancing
      - Optimizing communication and synchronization

  그래서 성능향상이 유니코어에 비해 더뎠다.

  ### SPEC CPU Benchmark

  퍼포먼스를 측정할 수 있는 프로그램이 있다. CINT2006을 reference machine(기준 기계)와 비교하여 몇 배 빠른지 측정

  ### SPEC Power Benchmark

  server side operation(단위 시간 당 끝낸 오퍼레이션 수)을 전력소모(단위 시간 당)로 나눈 것. -> 값이 클수록 전력당 많은 오퍼레이션을 수행한 것 == 좋은 것

  ## 1.9 Concluding Remarks

  ### Concluding Remarks

  - 가격대비 성능이 좋아지고 있다.(무어의 법칙)
  - Hierarchical layers of abstraction
  - ISA - the hardware/software interface
  - Execution time: 퍼포먼스에 대한 가장 좋은 측정 방법
  - Power는 성능 향상에 제약으로 작용 - parallelism을 써서 성능을 향상시키려 함

  ## 1.10 Fallacies and Pitfalls

  ### Pitfall: Amdahl's Law

  컴퓨터의 어느 한 부분의 성능을 향상시키면, 이에 비례하여 전체 성능이 향상된다.

  T(improved) = (T(affected)) / (improvement factor) + T(unaffected)

  특정 부분의 성능 향상은 그 부분이 전체 중에서 어느 정도의 비율을 가졌는지에 따라 다른 정도로 전체 성능 향상으로 이어진다.

  - 예제에 따르면, 곱하기의 성능 향상만으로는 전체 성능을 5배 향상시키는 건 불가능(해가 무한대)
    - 성능을 향상시키고자 하면 가장 많은 부분을 차지하는 것을 향상시키면 됨(**Corollary: make the common case fast**)

  ### Fallacy: Low Power at Idle

  CPU 10% 사용(load)해도 100% 사용에 비해 47%의 전력을 소모 -> 1차로 비례하지 않음

  구글의 데이터 센터도 대부분 10%-50% 로드로 사용됨.

  - Consider designing processors to make power proportional to load

  ### Pitfall: MIPS as a Performance Metric

  시간당 얼마나 많은 인스트럭션. but 문제가 있음

  -> 컴퓨터마다 ISA가 다르다.

  -> 명령마다 필요한 CPI 값이 다 다를 수 있음

  MIPS는 CPI에 의해 좌우됨 -> CPI는 프로그램 or CPU에 따라 달라질 수 있음 -> 정확한 성능 측정 단위라고 보기 어려움

  -> SPEC CPU benchmark 프로그램을 사용하는 것이 더 적절한 성능측정 방법